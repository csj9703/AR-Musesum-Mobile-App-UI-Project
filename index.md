## Welcome to the CPSC 481 Project page!

## Musemum App Project:
This project is an AR app aimed at people who like to visit museums. This app aims to replace the current standard of looking at the physical plaque descriptions at each display with being able to point your camera at an artifact and have the description appear on your phone or be read out to you. We also aim to provide more than just the text description of the artifacts, for example if the artifact is a dinosaur skeleton the app will allow users to see what scientists believe the dinosaur may have looked like, or if the artifact is a sword it can also display other relevant artifacts and related information such as the person who wielded the sword. The objective of this app is to transform the typical museum experience of just looking and reading into a more hands on and interactive experience, while also accommodating people with disabilities or language barriers by providing multiple ways to consume the information provided about exhibits. The goal is to engage and immerse users into the world of the artifacts.

## Project members:

  - [Amir Hussain](https://github.com/amir-hu)
  - [Alex Stark](https://github.com/Xelakrats)
  - [Bhavan Pahuja](https://github.com/BhavanPahuja)
  - [Israa Farouk](https://github.com/israa-farouk)
  - [Jason Chen](https://github.com/csj9703)
  
## Project Stages
<details>
  <summary><b>Stage one</b></summary>
<br>
<p>We have decided on three possible project ideas:</p>
  <ul>
    <li><b>A museum app</b></li>
  This app will display information for all artifacts and displays. It will accommodate things such as social distancing, people with visual impairment, and other ailments.  It will allow users to easily access information by the QR code/display displayed simply by taking an image. Allows for individuals to better their experiences in the museum as not having troubled by small quirks. Such as being in a place that’s too crowded to comfortably read the information, the text being too small or in a hard to read font, etc. It gives the user to customize how they receive the information. Implementing a QR reader/image recognition, to help identify what exhibit the user is pointing their camera at, through a mobile app.   
<li><b>A crime scene analysis tool</b></li>
    It is difficult to recreate a crime scene after it has been cleaned up. The tool provides opportunity for investigators to look back at details they may have missed and reduces the margin for human error. Reduces the chance of evidence being tampered with, and that in turn will lead to fewer wrongful convictions.  The software will create an AR recreation from a full scan of the original, untampered crime scene, which then allows investigators to look at the scene with fresh eyes and from different angles later. It will also allow users to examine and make notes on specific pieces of evidence that can be viewed in the AR environment. It will be implemented as computer software that allows the detectives to recreate and then examine the crime scene using images and dimensions. 
<li><b>A Fitness app</b></li>
    A fitness & dietary tracker to help a user track important aspect about their health, as well as ensure that the food they eat is within their dietary and caloric restrictions if they have any. This makes it convenient for users as everything to do with their health can easily be accessed in this app. Most trackers usually track one or the other, this app having it all in one package, will be very useful to the user.  It would be designed as a mobile app so that a user on the go can see if what they are buying in the store aligns with their dietary restrictions by simply scanning the nutrition facts, as well as tracking fitness data.  
 </ul> 
</details>

---

<details>
  <summary><b>Stage two</b></summary>
  <br>
  <p><b>For full report with images goes to https://github.com/csj9703/CPSC-481-Project/blob/stage_two/Stage%20Two%20Report.pdf</b></p>
  <p><b>We have decided on the idea of a AR museum app</b></p>
  <p><b>Project Description:</b></p>
  This project is an AR app aimed at people who like to visit museums. This app aims to replace the current standard of looking at the physical plaque descriptions at each display with being able to point your camera at an artifact and have the description appear on your phone or be read out to you. We also aim to provide more than just the text description of the artifacts, for example if the artifact is a dinosaur skeleton the app will allow users to see what scientists believe the dinosaur may have looked like, or if the artifact is a sword it can also display other relevant artifacts and related information such as the person who wielded the sword. The objective of this app is to transform the typical museum experience of just looking and reading into a more hands on and interactive experience, while also accommodating people with disabilities or language barriers by providing multiple ways to consume the information provided about exhibits. The goal is to engage and immerse users into the world of the artifacts.
  </p>
<p><b>Stakeholders & Users:</b></p>
  <ul>
  <li>Museum Visitors</li>
    <li>Museum Employees</li>
  </ul>
<p>User task descriptions:</p>
<ul>
  <li>Must be included</li>
  <ul>
    <li>Log in to museum system (visitor, staff, etc.)</li>
    <li>View exhibit description</li>
    <li>Artifact descriptions presented in multiple ways</li>
  </ul>
  <li>Important:</li>
  <ul>
    <li>Translation of exhibit description/Accessibility options</li>
    <li>A virtual tour guide</li></ul>
  <li>Could be included:</li>
  <ul>
    <li>Share visits on social media</li>
  <li>Show what areas of the museum have/have not been visited </li></ul>
</ul>
<p><b>IDEO cards:</b></p>
<ul>
  <li>Survey and Questionnaires (Ask)</li>
  <li>Competitive Product Survey (Learn)</li>
  <li>Scenarios (Try)</li>
  </ul>
  <p><b>Justifications:</b>
  <br>
  AR apps, despite having been around for many years, are not very common. Yes, many smart phones are capable, but no implementation has been made very popular. By conducting surveys and questionnaires, we can attempt to understand why many people do not use AR apps and what we can do to make an app that they are comfortable using. It will also allow us to see what museum goers would like to see in an app that might improve their experiences during their visits. We will then examine other museum apps that are currently in use to see if they are missing any features that our surveys indicate visitors might want, as well as to discover if there are any features that did not come up in the surveys. These comparisons also allow us to come up with ways to differentiate our project from what is already on the market so that we can develop the most competitive final product possible. Lastly, creating scenarios will force us to consider how different users might try to complete the various tasks that our app would include, which will give us the ability to create an app that is both useful and usable.  
</p>
<p>
  <b>Survey and Questionnaires (Ask):</b>
  <br><br>
  Survey the stakeholders about the current interactions between visitors and artifacts.
  <br><br>
  We surveyed potential museum visitors by publishing this link (https://survey.ucalgary.ca/jfe/form/SV_2sGpfmlJy7vIIU5) to our fellow classmates.
  <br><br>
  The survey asks 7 questions regarding augmented reality and museum experiences.
  <br><br>
  The things we learned from the survey:
  </p>
<ol>
  <li>Most participants had little to no experience in terms of augmented reality applications.</li>
  <li>Most participants have not used a museum app before.</li>
  <li>Most participants have difficulty reading the plaques.</li>
  <li>All the participants prefer more interactive experiences in a museum.</li>
  <li>Most participants prefer information be delivered visually.</li>
  <li>Most participants prefer the look of the exhibits.</li>
  <li>More than 50% of the participants find language a barrier during their visits.</li>
  </ol>
  <p><b>Competitive Product Survey (Learn):</b></p>
  <p>
  <b>British Museum Guide:</b></p>
  <p>The British museum is one of the most popular museums out there. They do some things well such as displaying a map of the museum showing where you have visited and where you have not. Gives you the ability to time your visits, that way if you only plan on staying for 2 hours it can tell you what you can see in that time. It gives a speech to text option as well and includes multiple pictures of each artifact.  
<br><br>
The app itself is very glitchy and does not seem to respond well. The pictures of the artifact seem to all be very similar and do not give enough perceptive. It does offer a speech to text however it is given in a robotic voice rather than an individual reading it with emotions.  
<br><br>
Map For Brtish Musuem Guide
This picture shows the map of the Musuem We plan on having our app display the map, and time your visits like the British museum app. However, we plan to make it a much smoother experience for the user. We intend on giving multiple viewpoints of the artifacts instead of a couple pictures, as well as options for animation, videos, etc. The speech to text will be involved but it will have a much better voice over to it as to show emotions in the readings. 
</p>
<p><b>Tourblink: British museum:</b></p>
<p>
The app first prompts the user to select a language and offers a smooth experience as well. The app only displays one picture per artifact, with audio description only allows few free playbacks with more locked behind in-app purchases. The biggest drawback is the app is limited to one location, that is, the user must download another Tourblink app if they wish to visit another museum. Another flaw being that although the app offers ticket sales, clicking the button takes the users to their own website which it offers tickets to every museum available, forcing the user to search through the website to find the ticket for the museum they are currently visiting. 
<br><br>
Our app will change the language based on the user’s phone settings. Moreover, we aim to have the app work universally for all museums, therefore, users will not have to download separate apps while visiting different museums. We will achieve that through scanning the user’s tickets, the app will detect the location and load the corresponding data (Descriptions, 3D models, animation, etc.) provided by the museum. 
</p>
<details><summary><b>Scenarios (Try):</b></summary>
  <p>
Vladimir Schmidtov is visiting from Russia and wants to see what museums are like in Britain. He has an auditory impairment, is paralyzed from the waist down, and speaks little to no English. He is a 69-year-old man who is at high risk due to the Covid-19 pandemic, so his top priority is safety. Once inside he has difficulty reading the plaques which display the information about exhibits. Since he is in a wheelchair, he has difficulty viewing the relics. He goes to an employee to ask for assistance, however she cannot understand him, and he cannot understand her. She points towards the multilingual posters for the app and he downloads it using the QR code on the poster.  
<br><br>
The app auto detects his phone language and sets it to Russian so he can understand the language. Once in the app, it prompts him to point toward an artifact, he points towards the Tipu Sultan sword and information about the sword appears. At first, he has difficulty reading the information, by using the menu on the app he increased the font and learned a lot about the sword. He also accesses information on how historians believed the sword was used. He was able to access this information in many formats, such as a YouTube video, Wikipedia page, or a 3D model. Once he had finished looking at the sword, he is greeted with a menu that displays unvisited areas/artifacts. Allowing him to choose what he wants to see next. This helps him to view all the artifacts in the museum and once he had done so he leaves the museum feeling well informed and immersed in the world of the relics he had just seen. 
</p>
  </details>
<p><b>Summary:</b></p>
<p>
This is one of many scenarios that showcase the usability and problem solving that this app is capable of. The key points to note are the ease of the use of the UI & the variety of ways the app showcases information. We wanted to create a situation that would have a lot of barriers. As to demonstrate how will out app fix issues many will come across. since a large demographic of museum visitors are the elderly, and most of the elderly are technologically illiterate. We wanted to ensure the UX is perfect for our app. It let us walk through what problems users may experience and what useful features we may need.
</p>
<details><summary><b>Research Reflections:</b></summary>
  <p><b>What went well:</b></p>
  <p>
    In terms of survey, we were able to get some responses from our classmates, friends, and family. And we were able to see a clear report provided by Qualtrics. 
  </p>
  <p>
  Competitive learning survey allowed us to see what our app needs to compete with. It showed us exactly what the competition looked like and what we need to achieve. It gave  us a standard and things we personally enjoyed from the app. We saw a lot of things that can be improved upon, as well as other ideas that should be introduced into our own projects. 
  </p>
  <p>
  Scenarios allowed us to look at our project and give a run through of how we believed the app to run through. By sitting down and looking at it we were able to see what problems a person may encounter and how we can help fix those problems. 
  </p>
  <p><b>What went poorly:</b></p>
  <p>
    For the survey, the amount of responses we obtained was not optimal, which may result in less accurate data being obtained. Because of the Covid-19 pandemic we could not actually go straight into a museum and try the app, rather we had to open the app and imagine what it could have been like. as for the scenario we were all a bit narrow minded as well, we attempted to come up with a person who would have the most difficulty with working the app , however in terms of technology we are all quite proficient at it. Which means none of us really know exactly what kind of scenario someone who is technologically challenged would have. Instead we had to make educational guesses as to where most people would struggle.  
  </p>
 </details>
</details> 

---

<details>
  <summary><b>Stage three</b></summary>
  <br>
  <p><b>For full report with images goes to https://github.com/csj9703/CPSC-481-Project/blob/stage_three/Stage%20Three%20Report.pdf</b></p>
<p><b>Project Description:</b></p>
  <p>
This project is an AR app aimed at people who visit museums. This app aims to replace thestandard of looking at the physical plaque descriptions with being able to point yourcamera at an artifact, scanning it, and seeing or hearing the corresponding description inthe app. The app also aims to provide AR models of artifacts with audio & visualdescriptions and allows users to then take pictures with these AR models and post them tosocial media. The artifacts can also have relevant animations that users can view. This appaims to transform the typical museum experience into a more hands on and interactiveone while also accommodating for people with disabilities or language barriers byproviding multiple ways to consume information provided about the exhibits
  </p>
<p><b>List of User Tasks that were prototyped Horizontally: </b></p>
<ul>
<li> User signs up for an account with the app.</li>
<li> User signs in to the app using Google/Facebook.</li>
<li> User signs in as a Guest.</li>
<li> User changes the app language from settings.</li>
<li> User changes the font size of the text in the app.</li>
<li> User selects a museum from listed nearby museums.</li>
<li> User selects a museum based on country and city.</li>
<li> User buys museum tickets by being redirected to the museum’s external website.</li>
<li> User leaves the selected museum page. </li>
 <li> User signs out of the app.</li>
</ul>
<p><b>List of User Tasks that were prototyped Vertically: </b></p>
<ul>
  <li> User scans an artiffact.</li>
  <ul>
    <li> User listens to an audio description about the scanned artifact.</li>
    <li> User reads a text description about the scanned artifact.</li>
    <li> User selects Videos to watch related videos about the scanned artifact.</li>
    <ul>
      <li> User selects one video from the list of related videos to watch.</li>
    </ul>
    <li> User places an artifact in AR.</li>
    <ul>
      <li> User listens to an audio description about the placed AR artifact.</li>
      <li> User reads text based AR info on the placed AR model.</li>
      <li> User views AR animation of the artifact.</li>
      <li> User takes a picture with the AR artifact.</li>
      <li> User shares the picture on social media.</li>
    </ul>
  </ul>
  <li> User takes a time based tour.</li>
  <ul>
    <li> User selects the desired end time of their tour.</li>
    <li> User selects the desired artifact to view.</li>
    <li> User scans an artifact.</li>
    <li> User views their current location on a mini map.</li>
    <li> User pauses their tour.</li>
    <li> User ends their tour.</li>
  </ul>
  <li> User interacts with a virtual map of the museum.</li>
  <ul>
    <li> User marks visited areas on the map.</li>
    <li> User unmarks accidentally marked areas on the map.</li>
    <li> User clears all markings on the map.</li>
    <li> User exits the map to go back to the museum home page.</li>
  </ul>
</ul>
  <p><b>Cognitive Evaluation</b></p>
  <p>
  We approached our cognitive evaluation through a user’s point of view. We carefullyexamined, analysed and noted every single step that we did for each of the tasks,evaluated if it was intuitive and if a typical user would know to do the same. We weremeticulous and included even minute steps such as clicking the next button as we wantedto make sure that everything we did was clear, thorough and concise.
  By examining the cognitive walkthrough for​ Task 1; Timed Tour​ we can see that we lead &direct the user too much. People may want different things from a tour, and currently weonly account for one type of customer; those who want to see artifacts in great detail.Some may just want a brief description through a small pop up explaining the artifact,while others may want information on the exhibit as a whole and not care too much abouteach individual artifact. We do not account for these possibilities and force the user to takethe tour in this more detailed artifact by artifact way
  By examining the cognitive walkthrough for ​Task 2; Virtual Map​ it is evident that we havea lot of oversights in our prototype. Most users don’t  want to have to read instructions onhow to use a certain feature in the app, however sometimes it is necessary. As seen in thiswalkthrough the user is left to put pieces together on their own, this may be intuitive tosome, however it is more likely to be unintuitive. This helped us see that perhaps we2
should add in some instructional boxes to help the user understand how to do certainthings .
Lastly by examining the cognitive walkthrough for​ Task 3; AR Display​  we realized that ARis not a common feature used by most apps, because of this we must assume people areunfamiliar with how it works. As a result we should have had an optional  tutorial on how touse the AR features in the app. Without this tutorial some users may be lost and be forcedto spend time figuring it out on their own, this may lead to a lot of users simply ignoring theAR features. Therefore, a way to familiarize users with AR is necessary.
One thing that we could have done to improve our cognitive walkthrough process is tohave teammates deal with the features that they were less familiar with (i.e they did notwork on the prototypes for these features). As this would have made it easier to look at thetasks with unbiased eyes and a fresh set of eyes would be able to see if the tasks were clearand intuitive.
</p>
<p><b>Refelction</b></p>
  <p>
Overall stage 3 went relatively smoothly for our team, we excelled in communication anddelegation. We held frequent meetings and shared all our work while in progress and aftercompletion this helped us all uphold the same level of consistency across our work anexample of this is; while we were creating our low-fidelity prototype we used the Balsamiqcloud feature, this gave us the ability to work on the wireframes in one place, this made iteasier to link wireframes together and be consistent with design features (Eg: look andcolour of buttons, etc) throughout our prototype even once tasks had been delegated.The only thing our team struggled with was creating the Affinity diagram, we all haddifferent understandings of what an affinity diagram was and this caused us to redo itmultiple times
From this I see the importance of discussion and planning before jumping right into thetask at hand as this saves time in the long run and if we were to do it again that is definitelysomething that should be done first. Another thing that we would have differently is todelegate the cognitive walkthrough tasks to team members that weren’t directly involved inthe designing of those tasks as this would give a more unbiased view of the intuitivenessand flow of the steps in the task.
  </p>
</details>
  
---

<details>
  <summary><b>Stage four</b></summary>
  <br>
  <p><b>For full report with images goes to LINK</b></p>
</details>

---

<details>
  <summary>Stage five</summary>
  <br>
  <p><b>To be added...</b></p>
</details>
